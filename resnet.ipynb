{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook I'm going to try using pretrained networks (or at least their architecture). I think that resnet will be ideal because of its generally good performance and due to the fact that it behaves like an exponential ensemble of networks with varying depth. From my preliminary results it seems like the small size of the images (75x75) and the small size of some of the features (5x5) will make models that are too deep--have lots of pooling layers--ineffective. I don't think resnet50 will work for 75x75 images, so I'll probably need to make a smaller model with similar architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "from fastai import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from keras.applications import resnet50\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "K.set_image_data_format('channels_first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vis import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Paths\n",
    "path = os.curdir + '/data/processed/composites/sample/'\n",
    "#path = os.curdir + '/data/processed/composites/'\n",
    "trn_path = path + 'train/'\n",
    "val_path = path + 'valid/'\n",
    "if os.path.exists(path+'models/')==False:\n",
    "    os.mkdir(path+'models')\n",
    "if os.path.exists(path+'results/')==False:\n",
    "    os.mkdir(path+'results/')\n",
    "model_path = path + 'models/'\n",
    "results_path = path + 'results/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batches = get_batches(trn_path)\n",
    "val_batches = get_batches(val_path, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_data = get_data(trn_path)\n",
    "val_data = get_data(val_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to stack them I need to remove the 1 in the reshape, the stacking takes care of the channel number\n",
    "band_1_s = np.array([np.array(band).astype(np.float32).reshape(75,75) for band in train.band_1])\n",
    "band_2_s = np.array([np.array(band).astype(np.float32).reshape(75,75) for band in train.band_2])\n",
    "bands = np.stack([band_1_s, band_2_s, (band_1_s+band_2_s)/0.5], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this will cause roughly 20% of the training set to be split out for validation\n",
    "msk = np.random.rand(len(train.band_1))<0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_data = bands[msk]\n",
    "val_data = bands[~msk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_data_transpose = np.array([np.array(image).reshape(3, 75*75).T for image in trn_data])\n",
    "val_data_transpose = np.array([np.array(image).reshape(3, 75*75).T for image in val_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_array(path + 'val_data', val_data)\n",
    "save_array(path + 'trn_data', trn_data)\n",
    "save_array(path + 'val_data_transpose', val_data_transpose)\n",
    "save_array(path + 'trn_data_transpose', trn_data_transpose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data = load_array(path + 'val_data')\n",
    "trn_data = load_array(path + 'trn_data')\n",
    "val_data_transpose = load_array(path + 'val_data_transpose')\n",
    "trn_data_transpose = load_array(path + 'trn_data_transpose')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#band_1 and band_2 share the same labels\n",
    "trn_labels = train.is_iceberg[msk]\n",
    "val_labels = train.is_iceberg[~msk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(path + 'models/')==False:\n",
    "    os.mkdir(path + 'models/')\n",
    "model_path = path + 'models/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resnet From Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ResNet50' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-fa9d0e291bb9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mResNet50\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'ResNet50' is not defined"
     ]
    }
   ],
   "source": [
    "rn = resnet50.ResNet50()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.gof.compilelock): Overriding existing lock by dead process '20310' (I am process '3167')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1237 samples, validate on 367 samples\n",
      "Epoch 1/3\n",
      "1237/1237 [==============================] - 22s 18ms/step - loss: 7.4532 - acc: 0.5376 - val_loss: 7.9493 - val_acc: 0.5068\n",
      "Epoch 2/3\n",
      "1237/1237 [==============================] - 22s 18ms/step - loss: 7.4532 - acc: 0.5376 - val_loss: 7.9493 - val_acc: 0.5068\n",
      "Epoch 3/3\n",
      "1237/1237 [==============================] - 21s 17ms/step - loss: 7.4532 - acc: 0.5376 - val_loss: 7.9493 - val_acc: 0.5068\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff447e80890>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rn.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "rn.fit(trn_data, trn_labels, batch_size=64, epochs=3, \n",
    "       validation_data=(val_data, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identity_block(input_tensor, kernel_size, filters, stage, block):\n",
    "    \n",
    "    filters1, filters2, filters3 = filters\n",
    "    if K.image_data_format() == 'channels_last':\n",
    "        bn_axis = 3\n",
    "    else:\n",
    "        bn_axis = 1\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "\n",
    "    x = Conv2D(filters1, (1, 1), name=conv_name_base + '2a')(input_tensor)\n",
    "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2a')(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(filters2, kernel_size,\n",
    "               padding='same', name=conv_name_base + '2b')(x)\n",
    "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2b')(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(filters3, (1, 1), name=conv_name_base + '2c')(x)\n",
    "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2c')(x)\n",
    "\n",
    "    x = add([x, input_tensor])\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def conv_block(input_tensor, kernel_size, filters, stage, block, strides=(2, 2)):\n",
    "    \"\"\"A block that has a conv layer at shortcut.\n",
    "    # Arguments\n",
    "        input_tensor: input tensor\n",
    "        kernel_size: default 3, the kernel size of middle conv layer at main path\n",
    "        filters: list of integers, the filters of 3 conv layer at main path\n",
    "        stage: integer, current stage label, used for generating layer names\n",
    "        block: 'a','b'..., current block label, used for generating layer names\n",
    "    # Returns\n",
    "        Output tensor for the block.\n",
    "    Note that from stage 3, the first conv layer at main path is with strides=(2,2)\n",
    "    And the shortcut should have strides=(2,2) as well\n",
    "    \"\"\"\n",
    "    filters1, filters2, filters3 = filters\n",
    "    if K.image_data_format() == 'channels_last':\n",
    "        bn_axis = 3\n",
    "    else:\n",
    "        bn_axis = 1\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "\n",
    "    x = Conv2D(filters1, (1, 1), strides=strides,\n",
    "               name=conv_name_base + '2a')(input_tensor)\n",
    "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2a')(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(filters2, kernel_size, padding='same',\n",
    "               name=conv_name_base + '2b')(x)\n",
    "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2b')(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(filters3, (1, 1), name=conv_name_base + '2c')(x)\n",
    "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2c')(x)\n",
    "\n",
    "    shortcut = Conv2D(filters3, (1, 1), strides=strides,\n",
    "                      name=conv_name_base + '1')(input_tensor)\n",
    "    shortcut = BatchNormalization(axis=bn_axis, name=bn_name_base + '1')(shortcut)\n",
    "\n",
    "    x = add([x, shortcut])\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def ResNet50():\n",
    "\n",
    "    img_input = Input(shape=(3,75,75))\n",
    "    \n",
    "    if K.image_data_format() == 'channels_last':\n",
    "        bn_axis = 3\n",
    "    else:\n",
    "        bn_axis = 1\n",
    "\n",
    "    x = Conv2D(\n",
    "        64, (7, 7), strides=(2, 2), padding='same', name='conv1')(img_input)\n",
    "    x = BatchNormalization(axis=bn_axis, name='bn_conv1')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
    "\n",
    "    x = conv_block(x, 3, [16, 16, 32], stage=2, block='a', strides=(1, 1))\n",
    "    x = identity_block(x, 3, [16, 16, 32], stage=2, block='b')\n",
    "    x = identity_block(x, 3, [16, 16, 32], stage=2, block='c')\n",
    "\n",
    "    x = conv_block(x, 3, [32, 32, 64], stage=3, block='a')\n",
    "    x = identity_block(x, 3, [32, 32, 64], stage=3, block='b')\n",
    "    x = identity_block(x, 3, [32, 32, 64], stage=3, block='c')\n",
    "    x = identity_block(x, 3, [32, 32, 64], stage=3, block='d')\n",
    "\n",
    "    #x = conv_block(x, 3, [256, 256, 1024], stage=4, block='a')\n",
    "    #x = identity_block(x, 3, [256, 256, 1024], stage=4, block='b')\n",
    "    #x = identity_block(x, 3, [256, 256, 1024], stage=4, block='c')\n",
    "    #x = identity_block(x, 3, [256, 256, 1024], stage=4, block='d')\n",
    "    #x = identity_block(x, 3, [256, 256, 1024], stage=4, block='e')\n",
    "    #x = identity_block(x, 3, [256, 256, 1024], stage=4, block='f')\n",
    "\n",
    "    #x = conv_block(x, 3, [512, 512, 2048], stage=5, block='a')\n",
    "    #x = identity_block(x, 3, [512, 512, 2048], stage=5, block='b')\n",
    "    #x = identity_block(x, 3, [512, 512, 2048], stage=5, block='c')\n",
    "\n",
    "    x = GlobalAveragePooling2D(name='avg_pool')(x)\n",
    "    x = Dense(1, activation='relu')(x)\n",
    "\n",
    "    model = Model(img_input, x, name='resnet50')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
